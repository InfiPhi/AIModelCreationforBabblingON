{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PodYlKy8Blxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb071d2-7742-406b-e059-bedeb857cf16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 75)        750       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 28, 28, 75)        300       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 75)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 50)        33800     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 50)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 14, 14, 50)        200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 50)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 25)          11275     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 7, 7, 25)          100       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 25)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               205312    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24)                12312     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 264049 (1.01 MB)\n",
            "Trainable params: 263749 (1.01 MB)\n",
            "Non-trainable params: 300 (1.17 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "215/215 [==============================] - 114s 524ms/step - loss: 1.0120 - accuracy: 0.6827 - val_loss: 3.6621 - val_accuracy: 0.1100\n",
            "Epoch 2/20\n",
            "215/215 [==============================] - 117s 546ms/step - loss: 0.2062 - accuracy: 0.9324 - val_loss: 1.7930 - val_accuracy: 0.4663\n",
            "Epoch 3/20\n",
            "215/215 [==============================] - 113s 526ms/step - loss: 0.0985 - accuracy: 0.9695 - val_loss: 0.0704 - val_accuracy: 0.9840\n",
            "Epoch 4/20\n",
            "215/215 [==============================] - 115s 535ms/step - loss: 0.0671 - accuracy: 0.9781 - val_loss: 0.0459 - val_accuracy: 0.9824\n",
            "Epoch 5/20\n",
            "215/215 [==============================] - 118s 550ms/step - loss: 0.0452 - accuracy: 0.9852 - val_loss: 0.0804 - val_accuracy: 0.9718\n",
            "Epoch 6/20\n",
            "215/215 [==============================] - 110s 514ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.1222 - val_accuracy: 0.9509\n",
            "Epoch 7/20\n",
            "215/215 [==============================] - 115s 535ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 0.0816 - val_accuracy: 0.9731\n",
            "Epoch 8/20\n",
            "215/215 [==============================] - 118s 550ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.0151 - val_accuracy: 0.9953\n",
            "Epoch 9/20\n",
            "215/215 [==============================] - 106s 494ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.4862 - val_accuracy: 0.8801\n",
            "Epoch 10/20\n",
            "215/215 [==============================] - 114s 529ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0226 - val_accuracy: 0.9936\n",
            "Epoch 11/20\n",
            "215/215 [==============================] - 110s 514ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0807 - val_accuracy: 0.9743\n",
            "Epoch 12/20\n",
            "215/215 [==============================] - 111s 515ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.1016 - val_accuracy: 0.9697\n",
            "Epoch 13/20\n",
            "215/215 [==============================] - 113s 525ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.1454 - val_accuracy: 0.9612\n",
            "Epoch 14/20\n",
            "215/215 [==============================] - 108s 502ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0229 - val_accuracy: 0.9941\n",
            "Epoch 15/20\n",
            "215/215 [==============================] - 108s 505ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.0191 - val_accuracy: 0.9921\n",
            "Epoch 16/20\n",
            "215/215 [==============================] - 116s 539ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0370 - val_accuracy: 0.9900\n",
            "Epoch 17/20\n",
            "215/215 [==============================] - 121s 562ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0125 - val_accuracy: 0.9965\n",
            "Epoch 18/20\n",
            "215/215 [==============================] - 108s 501ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 1.0030 - val_accuracy: 0.7963\n",
            "Epoch 19/20\n",
            "215/215 [==============================] - 108s 500ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.0545 - val_accuracy: 0.9813\n",
            "Epoch 20/20\n",
            "215/215 [==============================] - 106s 492ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0683 - val_accuracy: 0.9752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Load dataset\n",
        "train_df = pd.read_csv(\"sign_mnist_train.csv\")\n",
        "test_df = pd.read_csv(\"sign_mnist_test.csv\")\n",
        "\n",
        "# Separate labels\n",
        "y_train = train_df['label']\n",
        "y_test = test_df['label']\n",
        "del train_df['label']\n",
        "del test_df['label']\n",
        "\n",
        "# Binarize labels\n",
        "label_binarizer = LabelBinarizer()\n",
        "y_train = label_binarizer.fit_transform(y_train)\n",
        "y_test = label_binarizer.fit_transform(y_test)\n",
        "\n",
        "# Convert dataframes to numpy arrays\n",
        "x_train = train_df.values\n",
        "x_test = test_df.values\n",
        "\n",
        "# Normalize images\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Reshape images for CNN input\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# CNN Model Architecture ALEXNET\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(75, (3, 3), strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
        "\n",
        "\n",
        "model.add(Conv2D(50, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
        "\n",
        "\n",
        "model.add(Conv2D(25, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=24, activation='softmax'))  # 24 classes for ASL\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=128), epochs=20, validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "model.save('asl_model.h5')\n"
      ]
    }
  ]
}